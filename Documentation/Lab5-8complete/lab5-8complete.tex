\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,cite,enumerate,float,indentfirst}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{systeme}
\usepackage{hyperref}
\usepackage{url}
\usepackage[bottom]{footmisc}
\DeclareMathOperator{\med}{med}
\DeclareMathOperator{\sign}{sign}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\geometry{left=2cm}
\geometry{right=1.5cm}
\geometry{top=2cm}
\geometry{bottom=2cm}

\begin{document}
	
\begin{titlepage}
	\begin{center}		
		\vfill	
		Санкт-Петербургский политехнический университет \\
		Петра Великого\\
		\vskip 1cm
		Институт прикладной математики и механики \\
		Кафедра «Прикладная математика»
		\vfill
		\textbf{Отчёт\\
			по лабораторным работам №5-8\\
			по дисциплине\\
			«Математическая статистика»\\}
		\vfill
	\end{center}
	\vfill
	\hfill
	\begin{minipage}{0.4\textwidth}
		Выполнил студент:\\
		Самутичев Евгений Романович\\
		группа: 3630102/70201\\
	\end{minipage}
	\vfill
	\hfill 
	\begin{minipage}{0.4\textwidth}
		Проверил:\\
		к.ф.-м.н., доцент\\
		Баженов Александр Николаевич\
	\end{minipage}
	\vfill
	\begin{center}
		Санкт-Петербург\\2020 г.
	\end{center}
\end{titlepage}

\tableofcontents
\listoffigures
\listoftables
\pagebreak

\section{Постановка задачи}
\begin{enumerate}
	\item Сгенерировать двумерные выборки размера $20, 60, 100$ для нормального двумерного распределения $N(x, y, 0, 0, 1, 1, \rho)$.
	Коэффициент корреляции $\rho$ взять равным $0, 0.5, 0.9$
	Каждая выборка генерируется 1000 раз и для неё вычисляются: среднее значение, среднее значение квадрата и дисперсия коэффициентов
	корреляции Пирсона, Спирмена и квадрантного коэффициента корреляции.
	
	Повторить все вычисления для смеси нормальных распределений:
	$$f(x,y) = 0.9\cdot N(x, y, 0, 0, 1, 1, 0.9) + 0.1\cdot N(x, y, 0, 0, 10, 10, -0.9)$$.
	Изобразить сгенерированные точки на плоскости и нарисовать эллипс
	равновероятности.
	
	\item Найти оценки коэффициентов $a, b$ линейной регрессии $y_i = a + bx_i + \varepsilon_i$, используя 20 точек на отрезке $[-1.8, 2]$ с равномерным шагом равным 0.2. Ошибку $\varepsilon_i$ считать нормально распределённой с параметрами (0,1). В качестве эталонной зависимости взять $y_i = 2 + 2x_i + e_i$. При построении оценок коэффициентов использовать два критерия: критерий наименьших квадратов и критерий наименьших модулей. Проделать то же самое для выборки, у которой в значения $y_1$ и $y_2$ вносятся
	возмущения 10 и -10.
	
	\item Сгенерировать выборку объёмом 100 элементов для нормального распределения $N(0, 1)$. По сгенерированной выборке оценить параметры $\mu$ и $\sigma$ нормального закона методом максимального правдоподобия. В качестве основной гипотезы $H_0$ будем считать, что сгенерированное распределение имеет вид $N(\widehat{\mu}, \widehat{\sigma})$. Проверить основную гипотезу, используя критерий согласия $\chi^2$. В качестве уровня значимости взять $\alpha = 0.05$. Привести таблицу вычислений $\chi^2$. 
	
	\textbf{Дополнительное исследование:}\label{bonus} для проверки самого критерия, сгенерировать выборки объема 20, 100 для нормального распределения $U(-1, 1)$, после чего проверить их на <<нормальность>>.
	
	\item Для двух выборок размерами 20 и 100 элементов, сгенерированных согласно нормальному закону $N(0, 1)$, для параметров положения и масштаба построить асимптотически нормальные интервальные оценки на основе точечных оценок метода максимального правдоподобия и классические интервальные оценки на основе статистик $\chi^2$ и Стьюдента. В качестве доверительной вероятности взять $\gamma = 0.95$.
\end{enumerate}

\pagebreak

\section{Теория}
\subsection{Двумерное нормальное распределение}
Двумерная случайная величина $(X,Y)$ называется \textit{распределенной нормально} (или просто \textit{нормальной}) если её плотность вероятности определена формулой

\begin{equation}
\resizebox{.9\hsize}{!}{$
	N(x, y, m_1, m_2, \sigma_1, \sigma_2, \rho) = \frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}
	\exp{
		\left(-\frac{1}{2(1-\rho^2)} 
		\left[\frac{(x - m_1)^2}{\sigma_1^2} -
		2\rho\frac{(x - m_1)(y - m_2)}{\sigma_1\sigma_2} +
		\frac{(y - m_2)^2}{\sigma_2^2}\right]\right)
	}$}\label{eq:1}
\end{equation}

Можно показать \cite[стр. 133-134]{verrazdely} что компоненты $X,Y$ двумерной нормальной случайной величины также распределены нормально с математическими ожиданиями $m_X = m_1, m_Y = m_2$ и среднеквадратическими отклонениями $\sigma_X = \sigma_1, \sigma_Y = \sigma_2$. В свою очередь параметр $\rho$ - называют \textit{коэффициентом корреляции}. Его значение будет раскрыто далее.

\subsection{Ковариация и коэффициент корреляции}
\textit{Ковариацией} двух случайных величин $X$ и $Y$ называется величина:
\begin{equation}
	K_{XY} = \textbf{M} \left[ (X-m_X)(Y-m_Y) \right]
\end{equation}
В свою очередь \textit{коэффициентом корреляции} называется
\begin{equation}
	\rho_{XY} = \frac{K_{XY}}{\sigma_X \sigma_Y}
\end{equation}

Коэффициент корреляции характеризует зависимость между случайными величинами $X$ и $Y$. Именно его мы задаем в двумерном нормальном распределении как $\rho$. Если случайные величины$X$ и $Y$  независимы, то $\rho_{XY} = 0$ т.к. в этом случае очевидно $K_{XY} = 0$.

\subsection{Выборочные коэффициенты корреляции}
\subsubsection{Пирсона}
Пусть по выборке значений $\{x_i, y_i\}_{i=1}^n$ двумерной случайной величины $(X,Y)$. Естественной оценкой для $\rho_{XY}$ служит \textit{выборочный коэффициент корреляции (Пирсона)}:
\begin{equation}\label{eq:4}
	r = \frac{\frac{1}{n} \sum_{i=1}^{n}{(x_i - \bar{x})(y_i - \bar{y})}}
	{\sqrt{
			\frac{1}{n} \sum_{i=1}^{n}{(x_i-\bar{x})^2}
			\frac{1}{n} \sum_{i=1}^{n}{(y_i-\bar{y})^2}}}
\end{equation}
Важным для приложений свойством является то что при данной оценке гипотеза $\rho_{XY} \neq 0$ (о наличии зависимости между случайными) величинами может быть принята на уровне значимости $0.05$ если выполнено: 
\begin{equation}\label{eq:5}
	|r|\sqrt{n-1} > 2.5
\end{equation}
это можно найти к примеру в \cite[стр. 538]{verrazdely}

\subsubsection{Квадрантный}
\textit{Выборочным квадрантным коэффициентом корреляции} называется величина:
\begin{equation}\label{eq:6}
	r_Q = \frac{(n_1 + n_3) - (n_2 + n_4)}{n}
\end{equation}
, где $n_1, n_2, n_3, n_4$ - количества элементов выборки попавших соответственно в I, II, III и IV квадранты декартовой системы координат с центром в $(\med{x}, \med{y})$ и осями \\
$x_1 = x - \med{x}, y_1 = y - \med{y}$, где $\med$ - выборочная медиана.

Формулу (\ref{eq:6}) можно переписать эквивалентным образом:
\begin{equation}\label{eq:7}
	r_Q = \frac{1}{n}\sum_{i=1}^{n}{\sign(x_i -\med{x})\sign(y_i -\med{y})}
\end{equation}
Важным свойством этой оценки является робастность. Её мы можем проверить используя схему засорения (смесь нормальных распределений).

\subsubsection{Спирмена}
На практике нередко требуется оценить степень взаимодействия между качественными признаками изучаемого объекта. Качественным называется признак, который нельзя измерить точно, но который позволяет сравнивать изучаемые объекты между собой и располагать их в порядке убывания или
возрастания их качества. Для этого объекты выстраиваются в определённом порядке в соответствии с рассматриваемым признаком. Процесс упорядочения называется ранжированием, и каждому члену упорядоченной последовательности объектов присваивается ранг, или порядковый номер. \\

Например, объекту с наименьшим значением признака присваивается ранг 1, следующему за ним объекту — ранг 2, и т.д. Таким образом, происходит сравнение каждого объекта со всеми объектами изучаемой выборки. Если объект обладает не одним, а двумя качественными признаками — переменными $X$ и $Y$, то для исследования их взаимосвязи используют выборочный коэффициент корреляции между двумя последовательностями рангов этих признаков. \\

Обозначим ранги, соотвествующие значениям переменной $X$, через $u$, а ранги, соотвествующие значениям переменной $Y$ - через $v$. \textit{Выборочный коэффициент ранговой корреляции Спирмена} определяется как выборочный коэффициент корреляции Пирсона между рангами $u$, $v$ переменных $X, Y$:
\begin{equation}\label{eq:8}
	r_S = \frac
			{\frac{1}{n} \sum_{i=1}^{n}{(u_i - \bar{u})(v_i - \bar{v})}}
			{\sqrt{\frac{1}{n} \sum_{i=1}^{n}{(u_i-\bar{u})^2}
					\frac{1}{n} \sum_{i=1}^{n}{(v_i-\bar{v})^2}}}
\end{equation}

\subsection{Эллипс равновероятности}
Рассмотрим выражение для плотности двумерного нормального распределения (\ref{eq:1}) несколько подробнее, а именно найдем линии уровня или что равносильно проекции сечения графика плотности плоскостями параллельными $xOy$ на плоскость $xOy$:
$$N(x, y, m_1, m_2, \sigma_1, \sigma_2, \rho) = const$$
, или что равносильно:
\begin{equation}\label{eq:9}
	\frac{(x - m_1)^2}{\sigma_1^2} - 2\rho\frac{(x - m_1)(y - m_2)}{\sigma_1\sigma_2} + \frac{(y - m_2)^2}{\sigma_2^2} = const
\end{equation}

Во всех точках каждого из таких эллипсов плотность двумерного нормального распределения $N(x, y, m_1, m_2, \sigma_1, \sigma_2, \rho)$ постоянна. Поэтому они и называются \textit{эллипсами равновероятности}\cite[стр. 44-45]{ventzel}. Отметим что в предельном случае $\rho = 1$:
$$\left(\frac{x-m_1}{\sigma_1} - \frac{y-m_2}{\sigma_2}\right)^2 = const$$
, такое уравнение задает семейство прямых паралелельных прямой:
\begin{equation}\label{eq:10}
	\frac{x-m_1}{\sigma_1} = \frac{y-m_2}{\sigma_2}
\end{equation}
Аналогично рассматривается предельный случай $\rho = -1$.

В данной работе, для выборки построенной по распределению $N(x, y, m_1, m_2, \sigma_1, \sigma_2, \rho)$ эллипсы равновероятности строились таким образом чтобы покрыть все элементы выборки т.е. в качестве константы, стоящей в правой части уравнения (\ref{eq:9}) бралась:
\begin{equation}
	R = \max_{\{(x_i, y_i)\}_{i=1}^n}{\left(\frac{(x_i - m_1)^2}{\sigma_1^2} - 2\rho\frac{(x_i - m_1)(y_i - m_2)}{\sigma_1\sigma_2} + \frac{(y_i - m_2)^2}{\sigma_2^2}\right)}
\end{equation}

\subsection{Простая линейная регрессия}
Регрессионную модель описания данных называют \textit{простой линейной регрессией}, если
\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
\end{equation}
, где $\{x_i\}_{i=1}^n$ - значения фактора, $\{y_i\}_{i=1}^n$ - наблюдаемые значения отклика, а $\{\varepsilon_i\}_{i=1}^n$ - независимые, нормально распределенные по закону $N(0, \sigma)$ случайные величины, а $\beta_0, \beta_1$ - оцениваемые параметры\cite[стр. 507]{verrazdely}. Для оценки применяются различные методы, в данной работе рассмотрен следующий подход: вводится критерий рассогласования отклика и регрессионной функции, после чего оценки параметров регресии выводятся из задачи минимизации критерия. Рассмотрим два таких критерия.

\subsubsection{Критерий наименьших квадратов}
Достаточно простые расчетные формулы для оценок получают при выборе критерия в виде суммы квадратов отклонений значений отклика от значений регрессионной функции:
\begin{equation}\label{lab6:1}
Q\left(\beta_{0}, \beta_{1}\right)=\sum_{i=1}^{n} \varepsilon_i^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1} x_{i}\right)^{2} \rightarrow \min _{\beta_{0}, \beta_{1}}
\end{equation}

Приведем сами расчетные формулы \cite[стр. 509]{verrazdely}:
\begin{equation}
\widehat{\beta}_{1}=\frac{\overline{x y} - \bar{x} \cdot \bar{y}}{\overline{x^2} - (\bar{x})^{2}} \ \ \ \widehat{\beta}_{0}=\bar{y} - \bar{x} \widehat{\beta}_{1}
\end{equation}

Важным свойством является несмещенность оценки, однако она чувствительна к выбросам и если нужна робастная оценка, то следует рассмотреть следующий критерий.

\subsubsection{Критерий наименьших модулей}
В отличие от задач метода наименьших квадратов, для этого критерия минимизацию на практике проводят численно, решая:
\begin{equation}\label{lab6:2}
M\left(\beta_{0}, \beta_{1}\right)=\sum_{i=1}^{n}\left|y_{i}-\beta_{0}-\beta_{1} x_{i}\right| \rightarrow \min _{\beta_{0}, \beta_{1}}
\end{equation}

В данной работе был использован метод Нелдера-Мида \cite{nelder}, применимый к негладким функциям (в том числе к $M\left(\beta_{0}, \beta_{1}\right)$). Подробнее см. \hyperref[sec:impl]{реализация}.

\subsection{Точечное оценивание}
\subsubsection{Основные понятия}
Пусть имеется выборка $\{x_i\}_{i=1}^n$ из генеральной совокупности с плотностью распределения $f(x,\theta)$. Предполагается что функциональный вид зависимости задан с точностью до неизвестного параметра $\theta$. Требуется по выборке наблюдений $\{x_i\}_{i=1}^n$ определить число $\widehat{\theta}_n$ которое можно принять за значение параметра $\theta$. \textit{Точечной оценкой} неизвестного параметра $\theta$ распределения называется борелевская функция наблюдений $\widehat{\theta}_n = \widehat{\theta}_n(x_1, ..., x_n)$, приближенно равная $\theta$. Следует заметить что параметр может быть векторным, к примеру $\theta = (\mu, \sigma)$ для нормального распределения.

\subsubsection{Метод максимального правдоподобия}
Рассмотрим один общий метод построения точечных оценок. Для начала введем важное понятие, \textit{функцией правдоподобия} (ФП) называется совместная плотность вероятности распределения $n$ независимых с.в. $x_1, ..., x_n$:
\begin{equation}
L\left(x_{1}, \ldots, x_{n}, \theta\right)=f\left(x_{1}, \theta\right) f\left(x_{2}, \theta\right) \ldots f\left(x_{n}, \theta\right)
\end{equation}

Оценкой максимального правдоподобия (о. м. п.) будем называть такое значение $\widehat{\theta}_{\text{мп}}$ из множества допустимых значений параметра $\theta$, для которого ФП принимает наибольшее значение при заданных $x_1, ..., x_n$:
\begin{equation}
\widehat{\theta}_{\text{мп}}=\arg \max _{\theta} L\left(x_{1}, \ldots, x_{n}, \theta\right)
\end{equation}

Легко обобщается на случай векторного параметра $\theta = (\theta_1, ..., \theta_m)$:
\begin{equation}
\widehat{\theta}_{\text{мп}}=\arg \max _{\theta_1, ..., \theta_m} L\left(x_{1}, \ldots, x_{n}, \theta_1, ..., \theta_m\right)
\end{equation}

Известно \cite[стр. 444]{verrazdely} что о. м. п. нормального распределения являются выборочное среднее и выборочная дисперсия:
\begin{equation}
\widehat{\mu}_{\text{мп}} = \bar{x} \ \ \ \widehat{\sigma}_{\text{мп}} = \sqrt{s^2}
\end{equation}

\subsection{Критерий согласия $\chi^2$}
Для проверки гипотезы о законе распределения применяются различные критерии согласия. В данный работе рассматривается наиболее обоснованный и наиболее часто используемый в практике - критерий $\chi^2$ \cite[стр. 482]{verrazdely}. И так, выдвинута гипотеза $H_0$ о генеральном законе распределения с функцией распределения $F(x)$. Под конкурирующей гипотезой $H_1$ понимается гипотеза о справедливости одного из конкурирующих распределений.

Разобьем множество значений изучаемой случайной величины $X$ на $k$ непересекающихся подмножеств $\Delta_1, ..., \Delta_k$ и пусть $p_i = \textbf{P}(X \in \Delta_k)$. Если множество значений представляет вещественную ось, то подмножества имеют вид:

\begin{equation} 
\Delta_i = (a_{i-1}, a_i], i = 2, ...,k-1 \ \ \Delta_1 = (-\infty, a_1] \ \ \Delta_k = (a_{k-1}, +\infty)
\end{equation}

Пусть $n_1, ..., n_k$ - частоты попадания выборочных элементов в подмножества $\Delta_1, ..., \Delta_k$ соответственно. В случае справедливости гипотезы относительные частоты $\frac{n_i}{n}$ должны быть близки к $p_i$ при $i = 1, ..., k$. Поэтому за меру отклонения было предолжено (К. Пирсоном) \cite[стр. 483]{verrazdely} выбрать значение 
\begin{equation}
\chi^2_{B} = \sum_{i=1}^{k} \frac{n}{p_{i}}\left(\frac{n_{i}}{n}-p_{i}\right)^{2}=\sum_{i=1}^{k} \frac{\left(n_{i} - n p_{i}\right)^{2}}{n p_{i}}
\end{equation}

Существует \textbf{теорема}: \textit{статистика критерия $\chi^2$ асимптотически распределена по закону $\chi^2$ с $k-1$ степенями свободы}. На основе этой теоремы формируется правило проверки гипотезы о законе распределения по методу $\chi^2$: можно принять гипотезу $H_0$ на уровне значимости $\alpha$ если $\chi^2_{B} < \chi^2_{1-\alpha}$, в противном случае она отвергается.

В данной работе $k$ и длины $\Delta_1, ..., \Delta_k$ выбирались по правилам, которые обычно используют при построении гистограмм\cite{histogram}. Правило Райса для числа интервалов:
\begin{equation}
k = \lceil \ 1.72\sqrt[3]{n} \ \rceil 
\end{equation}
и правило Фридмена-Дайсона для ширины (считаем все интервалы кроме крайних одинаковой ширины)
\begin{equation}
a_i = \med{N(\widehat{\mu}, \widehat{\sigma})} + \left(i - \frac{k-1}{2}\right) h, \text{где } h = 2 \frac{\text{IQR} (x_1, ..., x_n)}{\sqrt[3]{n}}, i = 2, ..., k-1
\end{equation}
, где $\text{IQR}(x_1, ..., x_n)$ - выборочная интерквартильная широта, $\med{N(\widehat{\mu}, \widehat{\sigma})}$ - медиана гипотетического распределения (т.к. предполагается что именно в окрестности медианы будет большая часть элементов выборки).

\subsection{Интервальное оценивание}
\textit{Интервальной оценкой} (или \textit{доверительным интервалом}) числовой характеристики или параметра распределения $\theta$ генеральной совокупности с доверительной вероятностью $\gamma$ называется интервал $(\theta_1, \theta_2)$, границы которого являются случайными функциями: $\theta_1 = \theta_1 (x_1, ..., x_n), \theta_2 = \theta_2 (x_1, ..., x_n)$, который накрывает $\theta$ с вероятностью $\gamma$:
\begin{equation}
\mathbf{P}(\theta_1 < \theta < \theta_2) = \gamma
\end{equation}

Часто вместо доверительной вероятности $\gamma$ рассматривается  \textit{уровень значимости} $\alpha = 1 - \gamma$. Важной характеристикой данной интервальной оценки является половина длины доверительного интервала, она называется \textit{точностью} интервального оценивания
\begin{equation}
\Delta = \frac{\theta_2 - \theta_1}{2}
\end{equation}

\label{method}
Рассмотрим общий метод построения интервальных оценок \cite[стр. 456- -- 457]{verrazdely}. Пусть известна статистика $Y(\widehat{\theta}, \theta)$, содержащая оцениваемый параметр $\theta$ и его точечную оценку $\widehat{\theta}$ со следующими свойствами:
\begin{itemize}
	\item Функция распределения $F_Y (x)$ известна и не зависит от $\theta$
	\item Функция $Y (\widehat{\theta}, \theta)$ непрерывна и строго монотонна (для определенности - строго возрастает) по $\theta$
\end{itemize}
которые мы будем проверять при построении интервальных оценок нормального распределения. Зададим уровень значимости $\alpha$ и будем строить доверительный интервал так чтобы $(-\infty, \alpha_1), (\alpha_2, +\infty)$ накрывали $\theta$ с вероятностью $\frac{\alpha}{2}$. 

Пусть $y_{\alpha / 2}, y_{1 - \alpha / 2}$ -- квантили распределения $Y$ соотв. порядков, тогда
\begin{align}
\begin{split}
\textbf{P}\left(y_{\alpha / 2}<Y(\widehat{\theta}, \theta)<y_{1 - \alpha / 2}\right)=F_{Y}\left(y_{1-\alpha / 2}\right)-F_{Y}\left(y_{\alpha / 2}\right) &=\\
=1-\alpha / 2-\alpha / 2=1 &-\alpha=\gamma
\end{split}
\end{align}

Т.к. $Y(\widehat{\theta}, \theta)$ -- строго возрастает по $\theta$, то у неё есть обратная функция $Y^{-1}(y)$ относительно $\theta$ и она также строго возрастает, а значит:
\begin{align}
\begin{split}
y_{\alpha / 2} &< Y(\widehat{\theta}, \theta) < y_{1 - \alpha / 2} \\
Y^{-1}(y_{\alpha / 2}) &< \theta < Y^{-1}(y_{1 - \alpha / 2})
\end{split}
\end{align}
итого $\theta_1 = Y^{-1}(y_{\alpha / 2})$ и $\theta_2 = Y^{-1}(y_{1 - \alpha / 2})$ -- мы построили границы интервала. Применим это для построения интервальных оценок нормального распределения по выборке $(x_1, ..., x_n)$.

\subsection{Классические оценки}
\subsubsection{Для математического ожидания $m$}
Доказано что случайная величина $T = \sqrt{n-1} \cdot \frac{\bar{x} - m}{s}$ называемая статистикой Стьюдента, распределена по закону Стьюдента с $n-1$ степенями свободы, применяя с некоторыми деталями\cite[стр. 457 -- 458]{verrazdely} \hyperref[method]{выкладки}, получаем оценки границ интервала:
\begin{align}\label{lab8:1}
\begin{split}
m_1 &= \bar{x} - \frac{x t_{1 - \alpha / 2} (n-1)}{\sqrt{n-1}} \\
m_2 &= \bar{x} + \frac{x t_{1 - \alpha / 2} (n-1)}{\sqrt{n-1}}
\end{split}
\end{align}
, где $t_{1 - \alpha / 2}(n-1)$ -- квантиль порядка $1 - \alpha / 2$ распределения Стьюдента с $n-1$ степенями свободы.

\subsubsection{Для среднего квадратичного отклонения $\sigma$}
Доказано что случайная величина $n s^2 / \sigma^2$ распределена по закону $\chi^2$ с $n-1$ степенями свободы. Применяя общий \hyperref[method]{метод} построения интервальных оценок получаем оценки границ интервала:
\begin{align}\label{lab8:2}
\begin{split}
\sigma_1 &= \frac{s \sqrt{n}}{\sqrt{\chi_{1-\alpha / 2}^{2}(n-1)}} \\
\sigma_2 &= \frac{s \sqrt{n}}{\sqrt{\chi_{\alpha / 2}^{2}(n-1)}}
\end{split}
\end{align}
, где $\chi_{1 - \alpha / 2}^{2}(n-1), \chi_{\alpha / 2}^{2}(n-1)$ - квантили соотв. порядков $\chi^2$-распределения с $n-1$ степенями свободы.

\subsection{Асимптотически нормальные оценки}
\subsubsection{Для математического ожидания $m$}
В силу центральной предельной теоремы центрированная и нормированная случайная величина $\sqrt{n} (\bar{x} - m) / \sigma$ распределена приблизительно нормально с параметрами 0 и 1. Исходя из этого\cite[стр. 460]{verrazdely} получаем оценку:
\begin{align}\label{lab8:3}
\begin{split}
m_1 &= \bar{x} - \frac{s u_{1 - \alpha / 2}}{\sqrt{n}} \\
m_2 &= \bar{x} + \frac{s u_{1 - \alpha / 2}}{\sqrt{n}}
\end{split}
\end{align}
, где $u_{1 - \alpha /2}$ - квантиль нормального распределения $N(0, 1)$ порядка $1 - \alpha / 2$

\subsubsection{Для среднего квадратичного отклонения $\sigma$}
Аналогично, в силу центральной предельной теоремы центрированная и нормированная случайная величина $(s^2 - \mathbf{M}s^2) / \sqrt{\mathbf{D}s^2}$ при большом объеме выборки $n$ распределена приблизительно нормально с параметрами 0 и 1. Исходя из этого\cite[стр. 461]{verrazdely} получаем оценку:
\begin{align}\label{lab8:4}
\begin{split}
\sigma_1 &= s\left(1 + u_{1 - \alpha / 2} \sqrt{(e+2) / n}\right)^{-1 / 2} \\
\sigma_2 &= s\left(1 - u_{1 - \alpha / 2} \sqrt{(e+2) / n}\right)^{-1 / 2}
\end{split}
\end{align}
, где $e$ - выборочный эксцесс, определяемый как
\begin{equation}
e = \frac{m_4}{s^4} - 3
\end{equation}
, где $m_4$ - четвертый выборочный центральный момент, определяемый как
\begin{equation}
m_4 = \frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^4
\end{equation}
\pagebreak

\section{Реализация}
\label{sec:impl}
Работа выполнена с использованием языка \textbf{Python} в интегрированной среде разработки \textbf{PyCharm}, были задействованы библиотеки:

\begin{itemize}
	\item \textbf{NumPy} - векторизация вычислений, работа с массивами данных, вычисление выборочных характеристик
	\item \textbf{SciPy} - модуль \textbf{stats} для генерации данных по распределениям и эталонной зависимости, вычисления коэффициентов корелляции, оценок МНК, оценки методом максимального правдоподобия, модуль \textbf{optimize} для метода Нелдера-Мида
	\item \textbf{Matplotlib} - построение эллипсов рассеяния, построение графиков
\end{itemize}

Исходный код лабораторных работ приведен в приложении. 
\pagebreak

\section{Результаты}
\subsection{Коэффициенты корреляции}
\begin{table}[h!]
	\centering
	\input{tables/rho = 0.0.tex}
	\caption{$\rho = 0$}
\end{table}
\begin{table}[h!]
	\centering
	\input{tables/rho = 0.5.tex}
	\caption{$\rho = 0.5$}
\end{table}
\pagebreak

\begin{table}[h!]
	\centering
	\input{tables/rho = 0.9.tex}
	\caption{$\rho = 0.9$}
\end{table}

\begin{table}[h!]
	\centering
	\input{tables/mix.tex}
	\caption{Смесь нормальных распределений}
\end{table}
\pagebreak

\subsection{Эллипсы равновероятности}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.0, n = 20}
	\caption{$\rho = 0.0, n = 20$}
	\label{fig:image1}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.0, n = 60}
	\caption{$\rho = 0.0, n = 60$}
	\label{fig:image2}
\end{figure}
\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.0, n = 100}
	\caption{$\rho = 0.0, n = 100$}
	\label{fig:image3}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.5, n = 20}
	\caption{$\rho = 0.5, n = 20$}
	\label{fig:image4}
\end{figure}
\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.5, n = 60}
	\caption{$\rho = 0.5, n = 60$}
	\label{fig:image5}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.5, n = 100}
	\caption{$\rho = 0.5, n = 100$}
	\label{fig:image6}
\end{figure}
\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.9, n = 20}
	\caption{$\rho = 0.9, n = 20$}
	\label{fig:image7}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.9, n = 60}
	\caption{$\rho = 0.9, n = 60$}
	\label{fig:image8}
\end{figure}
\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{ellipse/rho = 0.9, n = 100}
	\caption{$\rho = 0.9, n = 100$}
	\label{fig:image9}
\end{figure}
\pagebreak

\subsection{Выборка без выбросов}
\begin{itemize}
	\item Критерий наименьших квадратов:
	$$\widehat{\beta}_0 = 2.47 \ \ \widehat{\beta}_1 = 1.95 \ \ Q\eqref{lab6:1} = 13.9637  \ \ M\eqref{lab6:2} = 13.9182$$
	\item Критерий наименьших модулей:
	$$\widehat{\beta}_0 = 2.49 \ \ \widehat{\beta}_1 = 1.68 \ \ Q = 15.9356 \ \ M = 13.3737$$
\end{itemize}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{regression/simple}
	\caption{Без выбросов}
	\label{fig:image10}
\end{figure}

\pagebreak
\subsection{Выборка с выбросами}
\begin{itemize}
	\item Критерий наименьших квадратов:
	$$\widehat{\beta}_0 = 2.61 \ \ \widehat{\beta}_1 = 0.52 \ \ Q  = 154.2302  \ \ M = 37.381$$
	\item Критерий наименьших модулей:
	$$\widehat{\beta}_0 = 2.67 \ \ \widehat{\beta}_1 = 1.35 \ \ Q = 172.7536 \ \ M = 29.9906$$
\end{itemize}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{regression/robust}
	\caption{С выбросами}
	\label{fig:image11}
\end{figure}
\pagebreak

\subsection{Критерий согласия $\chi^2$}
Оценки: 
\begin{equation}\label{lab7:1}
\widehat{\mu} = 0.03 \ \ \widehat{\sigma} = 1.01
\end{equation}
Число промежутков: $k = \lceil \ 1.72 \cdot \sqrt[3]{100} \ \rceil = 8$ \\ 

Таблица вычислений $\chi^2$:
\begin{table}[h!]
	\centering
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		$i$&$\Delta_i$		&$n_i$&$p_i$	&$n_i - np_i$  \\ \hline
		1&$(-\infty, -1.79]$&2    &0.0366  	&-1.6609  	\\ \hline
		2&$(-1.79, -1.27]$	&7    &0.0637	&0.627  	\\ \hline
		3&$(-1.27, -0.75]$	&12   &0.121	&-0.0972  	\\ \hline
		4&$(-0.75, -0.23]$	&22   &0.1777	&4.2306  	\\ \hline
		5&$(-0.23, 0.29]$	&22   &0.202	&1.8009    \\ \hline
		6&$(0.29, 0.81]$	&15   &0.1777	&-2.7694	\\ \hline
		7&$(0.81, 1.33]$	&8    &0.121   &-4.0972  	\\ \hline
		8&$(1.33, +\infty)$	&12   &0.1003	&1.9661  	\\ \hline
	\end{tabular}
	\caption{Таблица вычислений $\chi^2$}
\end{table}

При $\alpha = 0.05: \ \chi^2_{1-\alpha}(k-1) \approx 14.0671$, а вычисленное $\chi^2_{\text{B}} = 4.1883$, видно что \\ $\chi^2_{\text{B}} < \chi^2_{1-\alpha}(k-1)$

В результате \hyperref[bonus]{доп. исследования}, было получено что при $n = 20$ критерий дает вывод что генеральное распределение является нормальным $N(0.024, 0.59)$, в результате вычислений \\ $\chi^2_{B} = 4.8612 < 4.8784 = \chi^2_{1-\alpha}$, а при $n = 100$ уже $\chi^2_{B} = 19.2086 \geq 8.3834 = \chi^2_{1-\alpha}$ т.е. установлено что генеральное распределение не является нормальным (и это соответствует тому что оно задано как равномерное)

\subsection{Классические оценки}
\begin{equation*}
\begin{array}{|c|c|c|}
\hline 		& m\eqref{lab8:1} 	& \sigma\eqref{lab8:2} \\
\hline n=20	& -0.6 < m < 0.27	& 0.71 < \sigma < 1.36 \\
\hline n=100& -0.04 < m < 0.34 	& 0.84 < \sigma < 1.12 \\
\hline
\end{array}
\end{equation*}

\subsection{Асимптотически нормальные оценки}
\begin{equation*}
\begin{array}{|c|c|c|}
\hline 		& m\eqref{lab8:3} 	& \sigma\eqref{lab8:4} \\
\hline n=20	& -0.56 < m < 0.23 	& 0.71 < \sigma < 1.46 \\
\hline n=100& -0.03 < m < 0.34 	& 0.84 < \sigma < 1.13 \\
\hline
\end{array}
\end{equation*}
\pagebreak

\section{Обсуждение}
\subsection{Коэффициенты корреляции}
Для начала воспользуемся (\ref{eq:5}) для анализа экспериментов по которым были получены таблицы 1, 2. Выясним можно ли принять гипотезу о зависимости между случайными величинами на уровне значимости $\alpha = 0.05$ для $n = 100$ по коэффициенту Пирсона.
$$0 \sqrt{100 - 1} \leq 2.5, 4.98 \approx 0.5 \sqrt{100 - 1} > \cdot 2.5$$ 
В эксперименте 1 эту гипотезу принять нельзя, а в эксперименте 2 можно. При этом в эксперименте 1 с.в. заведомо независимы, а в эксперименте 2 зависимы, так что все согласуется с теорией. 

Из таблиц 1, 2 и 3 видно что $r, r_S$ являются состоятельными оценками $\rho_{XY}$ т.к. они все ближе к нему с ростом $n$.

Из таблицы 4 видим что $r_Q$ устойчивая к выбросам (робастная) оценка. Квадрантный коэффициент корреляции показывает лучшие результаты в устойчивости.

\subsection{Эллипсы равновероятности}
Видно что чем ближе $\rho$ к 1, тем эллипс равновероятности становится все больше похож на прямую, заданную как (\ref{eq:10}). Т.е. наглядно показано как между с.в. $X$ и $Y$ возникает линейная зависимость.

\subsection{Линейная регрессия}
Из графиков видно, что оценка по критерию наименьших модулей значительно лучше приближает эталонную зависимость при наличии выбросов и это согласуется с теорией т.к. она является робастной. В тоже время, критерий наименьших квадратов дает более точное приближение в отсутствие выбросов и, к тому же, проще для вычислений. Полученные значения $M, Q$ упорядочены как и ожидалось, для оценки МНК значение $Q$ меньше, чем для любой другой, аналогично для оценки МНМ и значения $M$ 

\subsection{Критерий согласия $\chi^2$}
Согласно результатам эксперимента, заданное по оценкам \eqref{lab7:1} распределение $N(\widehat{\mu}, \widehat{\sigma})$ является генеральным законом по которому построена выборка с уровнем значимости $0.05$. Теоретически это обосновывается тем что оценки максимального правдоподобия состоятельны. Было установлено что при небольших объемах выборки уверенности в полученных результатах нет, ведь статистика критерия $\chi^2$ лишь асимптотически распределена по закону $\chi^2 (k-1)$ т.е. $n$ предполагается достаточно большим.

\subsection{Интервальное оценивание}
Полученные интервальные оценки говорят о том что с вероятностью $0.95$ значения $m = 0$ и $\sigma = 1$ лежат в соответствующих интервалах. По постановке эксперимента, интервалы действительно накрывают истинные значения параметров. Следует заметить что при большом объеме $n$ выборки - асимптотические оценки практически совпадают с классическими.
\pagebreak

\section{Приложения}\label{sec:appl}
\noindent 1. Исходный код лабораторной 5 {\url{https://github.com/zhenyatos/statlabs/tree/master/Lab5}} \\
\noindent 2. Исходный код лабораторной 6 {\url{https://github.com/zhenyatos/statlabs/tree/master/Lab6}} \\
\noindent 3. Исходный код лабораторной 7 {\url{https://github.com/zhenyatos/statlabs/tree/master/Lab7}} \\
\noindent 4. Исходный код лабораторной 8 {\url{https://github.com/zhenyatos/statlabs/tree/master/Lab8}}

\begin{thebibliography}{9} 
	\bibitem{verrazdely} \textbf{Вероятностные разделы математики.} Учебник для бакалавров технических направлений. // Под ред. Максимова Ю.Д. - СПб <<Иван Федоров>>, 2001. - 592 с., илл
	
	\bibitem{ventzel} Вентцель Е.С. \textit{Теория вероятностей: Учеб. для вузов.} — 6-е изд. стер. — М.: Высш. шк., 1999.— 576 c.
	
	\bibitem{nelder} Метод Нелдера — Мида // Википедия. [2019—2019]. Дата обновления: 11.09.2019. URL: https://ru.wikipedia.org/?oldid=102111276 (дата обращения: 11.09.2019).
	
	\bibitem{histogram} Wikipedia contributors. (2020, March 19). Histogram. In Wikipedia, The Free Encyclopedia. Retrieved 18:27, May 14, 2020, from \url{https://en.wikipedia.org/w/index.php?title=Histogram&oldid=946321806}
\end{thebibliography}

\end{document}
